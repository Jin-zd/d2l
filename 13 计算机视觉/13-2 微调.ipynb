{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-29T04:16:15.491617Z",
     "start_time": "2024-10-29T04:16:10.686946Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "import tools as tl"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-29T04:17:14.109565Z",
     "start_time": "2024-10-29T04:16:43.331869Z"
    }
   },
   "cell_type": "code",
   "source": "data_dir = tl.download_extract('hotdog')",
   "id": "a1d920efb8836ea6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ..\\data\\hotdog.zip from http://d2l-data.s3-accelerate.amazonaws.com/hotdog.zip...\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "train_images = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'train'))\n",
    "test_images = torchvision.datasets.ImageFolder(os.path.join(data_dir, 'test'))"
   ],
   "id": "e60930791782452e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "hotdogs = [train_images[i][0] for i in range(8)]\n",
    "not_hotdogs = [train_images[-i - 1][0] for i in range(8)]\n",
    "tl.show_images(hotdogs + not_hotdogs, 2, 8, scale=1.4)\n",
    "tl.plt.show()"
   ],
   "id": "4a5a7b4c30e78d53"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "normalize = torchvision.transforms.Normalize(\n",
    "    [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "\n",
    "train_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.RandomResizedCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])\n",
    "\n",
    "test_augs = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    normalize])"
   ],
   "id": "6a63ac2f06289a87"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pretrained_net = torchvision.models.resnet18(pretrained=True)",
   "id": "6ba8da9ed894e070"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pretrained_net.fc",
   "id": "97419427d9ae3ced"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "finetune_net = torchvision.models.resnet18(pretrained=True)\n",
    "finetune_net.fc = nn.Linear(finetune_net.fc.in_features, 2)\n",
    "nn.init.xavier_uniform_(finetune_net.fc.weight)"
   ],
   "id": "cea019a8ef6d1e1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train_fine_tuning(net, learning_rate, batch_size=128, num_epochs=5\n",
    "                      , param_group=True):\n",
    "    train_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'train'), transform=train_augs),\n",
    "        batch_size, shuffle=True)\n",
    "    test_iter = torch.utils.data.DataLoader(torchvision.datasets.ImageFolder(\n",
    "        os.path.join(data_dir, 'test'), transform=test_augs),\n",
    "        batch_size)\n",
    "    devices = tl.try_all_gpus()\n",
    "    loss = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "    if param_group:\n",
    "        params_1x = [param for name, param in net.named_parameters()\n",
    "                     if name not in ['fc.weight', 'fc.bias']]\n",
    "        trainer = torch.optim.SGD([{'params': params_1x}, {'params': net.fc.parameters(), 'lr': learning_rate * 10}],\n",
    "                                  lr=learning_rate, weight_decay=0.001)\n",
    "    else:\n",
    "        trainer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=0.001)\n",
    "    tl.train_ch13(net, train_iter, test_iter, loss, trainer, num_epochs, devices)"
   ],
   "id": "e0caf2c892e0f884"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_fine_tuning(finetune_net, 5e-5)",
   "id": "86b2a916fb1ce51b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "scratch_net = torchvision.models.resnet18()\n",
    "scratch_net.fc = nn.Linear(scratch_net.fc.in_features, 2)\n",
    "train_fine_tuning(scratch_net, 5e-4, param_group=False)"
   ],
   "id": "9aca210245678350"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
